{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Por favor adicione o diretorio de trabalho? C:\\github\\Kaggle_Challenges\\ML_Competitions\\data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "path = input('Por favor adicione o diretorio de trabalho?')\n",
    "for dirname, _, filename in os.walk(path, topdown = True):\n",
    "    for filename in filename:\n",
    "        if filename == 'test.csv':\n",
    "                teste = pd.read_csv(os.path.join(dirname,filename))\n",
    "        else:\n",
    "            if filename == 'train.csv':\n",
    "                treino = pd.read_csv(os.path.join(dirname,filename))\n",
    "            else:\n",
    "                print(\"Deu ruim irmão!!\")\n",
    "            \n",
    "X = treino.drop('Cover_Type',axis=1) \n",
    "y= treino.Cover_Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\sklearn\\mixture\\base.py:265: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  % (init + 1), ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Testando quantidade de componentes\n",
    "n_components = np.arange(1, 35)\n",
    "models = [GaussianMixture(n, covariance_type='full',reg_covar=1, random_state=0).fit(teste)\n",
    "          for n in n_components]\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12,8))\n",
    "plt.plot(n_components, [m.aic(teste) for m in models], label='AIC')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('n_components');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gerando os Grupos\n",
    "\n",
    "gmix = GaussianMixture(n_components = 22)\n",
    "gmix.fit(teste)\n",
    "\n",
    "#Separando X e Y\n",
    "X_mix = treino.drop('Cover_Type', axis =1)\n",
    "y_mix = treino['Cover_Type']\n",
    "\n",
    "treino['Cluster_teste'] = gmix.predict(X_mix)\n",
    "teste['Cluster_teste'] = gmix.predict(teste)\n",
    "\n",
    "# Gerando os novos datasets\n",
    "\n",
    "treino.to_csv('train.csv')\n",
    "teste.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analise das variáveis de distância."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acrecentando variavel com a distancia euclideana entre as distancias para água.\n",
    "def euc_dist(df):\n",
    "    cols = ['Elevation', 'Horizontal_Distance_To_Hydrology','Horizontal_Distance_To_Fire_Points']\n",
    "    df['Euclidean_Dist'] = np.sqrt((df.Vertical_Distance_To_Hydrology**2 + df.Horizontal_Distance_To_Hydrology**2))\n",
    "    df['Dist_Meam'] = df[cols[0:]].mean(axis=1)\n",
    "    df['Vertical_Diff'] = df['Elevation']-df['Vertical_Distance_To_Hydrology']\n",
    "    return df\n",
    "\n",
    "euc_dist(treino)\n",
    "euc_dist(teste)\n",
    "\n",
    "treino.to_csv('train.csv')\n",
    "teste.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analise Elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elevation(df):\n",
    "    #df['Elevationlog'] = np.log1p(df['Elevation'])\n",
    "    #df['Elevation2'] = df['Elevation']**2\n",
    "    df['ElevationEUC'] = df['Elevation']*df['Euclidean_Dist'] \n",
    "    df['ElevationV'] = df['Elevation']*df['Vertical_Distance_To_Hydrology']\n",
    "    df['ElevationH'] = df['Elevation']*df['Horizontal_Distance_To_Hydrology']\n",
    "    return df\n",
    "\n",
    "elevation(treino)\n",
    "elevation(teste)\n",
    "\n",
    "treino.to_csv('train.csv')\n",
    "teste.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspect vs Slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AspxSlop(df):\n",
    "    df['AspxSlp'] = df['Aspect']*df['Slope']\n",
    "    df['AspxSlp_Noon'] = df['Aspect']*df['Slope']*df['Hillshade_Noon']\n",
    "    df['AspxSlp_3pm'] = df['Aspect']*df['Slope']*df['Hillshade_3pm']\n",
    "    df['AspxSlp_9am'] = df['Aspect']*df['Slope']*df['Hillshade_9am']\n",
    "    return df\n",
    "\n",
    "AspxSlop(treino)\n",
    "AspxSlop(teste)\n",
    "\n",
    "treino.to_csv('train.csv')\n",
    "teste.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analise das variaveis Shades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shade(df):\n",
    "    SHADES = ['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']\n",
    "    \n",
    "    df['shade_noon_diff'] = df['Hillshade_9am'] - df['Hillshade_Noon']\n",
    "    df['shade_3pm_diff'] = df['Hillshade_Noon'] - df['Hillshade_3pm']\n",
    "    df['shade_all_diff'] = df['Hillshade_9am'] - df['Hillshade_3pm']\n",
    "    df['shade_sum'] = df[SHADES].sum(axis=1)\n",
    "    df['shade_mean'] = df[SHADES].mean(axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "shade(treino)\n",
    "shade(teste)\n",
    "\n",
    "treino.to_csv('train.csv')\n",
    "teste.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Willderness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def will(df):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analise das variáveis de Solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somando as variavies de Solo\n",
    "def solo_sum(df):\n",
    "    cols=  ['Soil_Type1', 'Soil_Type2', 'Soil_Type3',\n",
    "       'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8',\n",
    "       'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12',\n",
    "       'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16',\n",
    "       'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n",
    "       'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n",
    "       'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n",
    "       'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n",
    "       'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n",
    "       'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40']\n",
    "    \n",
    "    df['Soil_Sum'] = df[cols].sum(axis=1)\n",
    "    return df\n",
    "\n",
    "solo_sum(treino)\n",
    "solo_sum(teste)\n",
    "\n",
    "treino.to_csv('train.csv')\n",
    "teste.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerando dados artificias da classe 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
